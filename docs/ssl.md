SSL certificates are issed by LetsEncrypt using the DNS-01 protocol.

Each leaf gets a cert that is valid for leafname.rippy.rip _and_ irc.rippy.rip.

The hub is in charge of issuing certificates and distributing them to the leaves.

The hub has a user 'ssl-controller'. This user has:

* An SSH key that is in the the authorized_keys file for the user 'ssl' on each leaf server
* The LetsEncrypt API key (generated by the initial setup Ansible playbook)
* The CloudFlare DNS API key (provided to the playbook by us)

The user will periodically (once a day?) run an Ansible policy that will:

* Check if the certs on any leaf are invalid or nearing expiry
* If so, issue a new one by changing DNS with CloudFlare and talking to LetsEncrypt
* Upload this cert to the leaf
* Reload the IRC server config on the leaf to pick up the new key

The leaves will have a user 'ssl' which will have no special permissions, but is able to:

* copy the SSL cert in place (it has write perms over the directory it resides in and ownership of the file)
* reload the IRC server config (via a passwordless sudo entry for this specific command)

There is also a new o:line for a user "ssl" who can just rehash the config - this is necessary so the ssl user can log in over IRC and reload the SSL cert (which doesn't happen with a normal rehash).

# Ansible policies

There are two:

* `./playbook.yml` - this performs initial setup, creating users, generating LE key, etc, that only needs to be done once. This is run from our machines and needs to be run on all the hub/leaf servers together by someone with root access to all of them.
* `./ssl-controller-policy/playbook.yml` - this is a multi-file policy that is uploaded to the hub (by the initial setup policy) and is the one that runs regularly to actually update the certificates.

# Files

The Lets Encrypt account key will be stored in

`/home/ssl-controller/account-key.pem`

The IRC certificate is still in the same place as before:

`/etc/inspircd/cert.pem`

But now it is owned by the ssl user, and is world-readable.

The parent directory for this is now owned by the user 'irc' and the group 'ssl', so the ssl user can read the dir and create certs and the IRCd can read them (the rest of the config files are irc:irc and not readable by ssl).

`secrets.yml`

Various items we don't want to store in Git are fed to the ssl-controller Ansible policy via this file.

# Running in development

First, run:

`vagrant provision --provision-with=ansible`

This runs an Ansible policy that doesn't actually do anything, but prompts Vagrant to create inventory files for Ansible that point at the virtual machines.

Then to run the initial setup policy:

`make`

Or if initial setup hasn't changed and you only want to upload ssl-controller-policy:

`make quick`

# Run options

Just do the thing:

```
ansible-playbook -u ssl -i hosts.ini playbook.yml
```

Do the thing on just one of the leaves with `--limit`:

```
ansible-playbook -i hosts.ini --limit eu playbook.yml
```

Run in "blind upload" mode - this mode doesn't assume Inspircd is running, so it won't make any checks against the IRCd, rehash it, or confirm deployment of the certificate. Useful if Inspircd won't start until it has a certificate!

```
ansible-playbook -i hosts.ini -e 'blind_upload=true' playbook.yml
# or:
BLIND_UPLOAD=true ansible-playbook -i hosts.ini playbook.yml
```

# Initial deployment

The first deployment is complicated by the fact that these files are still under CFEngine's control, but it's Ansible that adds the new user.

Here's the play-by-play for the initial deployment:

1. Run the Ansible initial setup policy which will create the users, dirs, etc
2. Create secrets.yml
3. Upload (and run) the new CFEngine policy to set new permissions on config dir & cert
4. Run the issue certificates policy normally, which will then rehash Inspircd configuration and SSL
